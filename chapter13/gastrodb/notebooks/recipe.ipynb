{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate, os\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "# from langchain.vectorstores import Weaviate    \n",
    "# from langchain.document_loaders import PyPDFLoader\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "AZURE_OPEN_AI_ORGANIZATION = os.getenv('OPEN_AI_ORGANIZATION')\n",
    "\n",
    "\n",
    "client = weaviate.connect_to_local(\n",
    "    # host=\"0.0.0.0\",  # Use a string to specify the host\n",
    "    port=8083,\n",
    "    grpc_port=50051,\n",
    ")\n",
    "\n",
    "print(client.is_ready())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "collection_name = \"test_collection\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list collections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Schema definiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_definition= {       \n",
    "    \"class\": \"RecipeOpenAI\",\n",
    "    \"description\": \"Document from github or stackoverflow\",\n",
    "    \"vectorizer\": \"text2vec-openai\",\n",
    "    \"vectorIndexConfig\": {\n",
    "        \"distance\": \"cosine\" # Set to \"cosine\" for English models; \"dot\" for multilingual \n",
    "    },\n",
    "    \"moduleConfig\": {\n",
    "        \"text2vec-openai\": {\n",
    "            \"resourceName\":AZURE_OPEN_AI_ORGANIZATION,\n",
    "            \"deploymentId\": \"text-embedding-ada-002\"\n",
    "        },\n",
    "        \"generative-openai\": {\n",
    "            \"resourceName\":AZURE_OPEN_AI_ORGANIZATION,\n",
    "            \"deploymentId\": \"gpt-35-turbo\"\n",
    "            },\n",
    "    },\n",
    "    \"properties\": [\n",
    "        {\n",
    "            \"name\": \"docSource\",\n",
    "            \"description\": \"Type of document ('learn', 'astro', 'airflow', 'stackoverflow', 'code_samples')\",\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"moduleConfig\": {\n",
    "                \"text2vec-openai\": {\n",
    "                    \"skip\": \"False\",\n",
    "                    \"vectorizePropertyName\": \"False\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"docLink\",\n",
    "            \"description\": \"The url of source data\",\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"tokenization\": \"field\",\n",
    "            \"moduleConfig\": {\n",
    "                \"text2vec-openai\": {\n",
    "                    \"skip\": \"True\",\n",
    "                    \"vectorizePropertyName\": \"False\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_schema(class_definition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n",
    "embeddings = AzureOpenAIEmbeddings(model=\"text-embedding-ada-002\", client=client )\n",
    "\n",
    "\n",
    "# import first article\n",
    "loader = PyPDFLoader(\"brazil-wikipedia-article-text.pdf\", extract_images=False)\n",
    "docs = loader.load_and_split(text_splitter)\n",
    "print(f\"GOT {len(docs)} docs for Brazil\")\n",
    "\n",
    "idx = [i*16 for i in range(int(len(docs) /16+1))] + [len(docs)]\n",
    "\n",
    "for i in range(len(idx) - 1):\n",
    "    Weaviate.from_documents(\n",
    "        docs[idx[i]:idx[i+1]], \n",
    "        embeddings, \n",
    "        index_name=\"RecipeOpenAI\", \n",
    "        client=client, \n",
    "        by_text=False\n",
    "    )\n",
    "\n",
    "\n",
    "# import second article\n",
    "loader = PyPDFLoader(\"netherlands-wikipedia-article-text.pdf\", extract_images=False)\n",
    "docs = loader.load_and_split(text_splitter)\n",
    "print(f\"GOT {len(docs)} docs for Netherlands\")\n",
    "\n",
    "\n",
    "# divide documents in 16 chunks\n",
    "idx = [i*16 for i in range(int(len(docs) /16+1))] + [len(docs)]\n",
    "\n",
    "\n",
    "for i in range(len(idx) - 1):\n",
    "    Weaviate.from_documents(\n",
    "        docs[idx[i]:idx[i+1]], \n",
    "        embeddings, \n",
    "        index_name=\"RecipeOpenAI\", \n",
    "        client=client, \n",
    "        by_text=False\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = (\n",
    "    client.query\n",
    "    .aggregate(\"RecipeOpenAI\")\n",
    "    .with_fields(\"source { count type topOccurrences { occurs value } }\")\n",
    "    .do()\n",
    ")\n",
    "\n",
    "print(json.dumps(response, indent=2))\n",
    "\n",
    "# Let's query some objects\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"RecipeOpenAI\", \"text source\")\n",
    "    .with_limit(4)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets do a RAG directly using only Weaviate\n",
    "\n",
    "# This is our prompt.\n",
    "generateTask = \"Quelle est la nourriture traditionnelle de ce pays ? Answer in Spanish\"\n",
    "# lets filter it out, and only use this specific file\n",
    "source_file = \"brazil-wikipedia-article-text.pdf\"\n",
    "\n",
    "result = (\n",
    "  client.query\n",
    "  .get(\"RecipeOpenAI\", \"text\")\n",
    "  .with_generate(grouped_task = generateTask)\n",
    "  .with_where({\n",
    "      \"operator\": \"Equal\",\n",
    "      \"path\": [\"source\"],\n",
    "      \"valueText\": source_file\n",
    "  })\n",
    "  .with_near_text({\n",
    "   \"concepts\": [\"tradicional Food\"]\n",
    "  })\n",
    "  .with_limit(5).do()\n",
    ")\n",
    "\n",
    "print(json.dumps(result, indent=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Weaviate(client=client, index_name=\"RecipeOpenAI\", text_key=\"text\", embedding=embeddings)\n",
    "docs = db.similarity_search(\"traditional food\")\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Text: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer the question based on the text provided. If the text doesn't contain the answer, \n",
    "reply that the answer is not available.\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import AzureChatOpenAI  \n",
    "\n",
    "\n",
    "\n",
    "# Let's answer some question\n",
    "#source_file = \"brazil-wikipedia-article-text.pdf\"\n",
    "source_file = \"netherlands-wikipedia-article-text.pdf\"\n",
    "where_filter = {\n",
    "      \"operator\": \"Equal\",\n",
    "      \"path\": [\"source\"],\n",
    "      \"valueText\": source_file\n",
    "  }\n",
    "\n",
    "# we want our retriever to filter the results\n",
    "retriever = db.as_retriever(search_kwargs={\"where_filter\": where_filter})\n",
    "\n",
    "openai_client = AzureChatOpenAI(\n",
    "    model_name=\"gpt-35-turbo\", \n",
    "    deployment_name = \"gpt-35-turbo\",\n",
    "    # azure_endpoint=AZURE_OPEN_AI_BASE_URL,\n",
    "    )\n",
    "\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=openai_client, \n",
    "                                 chain_type=\"stuff\", #map_reduce\n",
    "                                 retriever=retriever, \n",
    "                                 chain_type_kwargs=chain_type_kwargs, \n",
    "                                 return_source_documents=True)\n",
    "                                 \n",
    "answer = qa({\"query\": \"What is the traditional food of this country?\"})\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from airflow.models.connection import Connection\n",
    "\n",
    "c = Connection(\n",
    "    conn_id='weaviate_default',\n",
    "    conn_type='weaviate',\n",
    "    host='http://weaviate:8083/',\n",
    ")\n",
    "print(f\"AIRFLOW_CONN_{c.conn_id.upper()}='{c.get_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"/home/isma/repos/book/data-pipelines-with-airflow-2nd-ed/chapter13_genai/recipe_book/notebooks/splitted (1).parquet\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.chunk[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.chunk[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.environ.pop(\"X-Azure-Api-Key\", None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.environ.pop(\"X-Azure-Api-Key\", None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.environ.pop(\"AZURE_API_KEY\", None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AZURE_API_KE\"] = \"22\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  os.environ[\"X-Azure-Api-Ke\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
